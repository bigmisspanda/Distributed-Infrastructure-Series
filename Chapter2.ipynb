{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7DlSrBmp7VJ"
      },
      "source": [
        "## Chapter 2: Loading a Quantized Model"
      ],
      "id": "X7DlSrBmp7VJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-4TsbHkp7VM"
      },
      "source": [
        "### Spoilers\n",
        "\n",
        "In this chapter, we’ll:\n",
        "\n",
        "- Understand how quantization works\n",
        "- Explore the pros and cons of using different data types (FP16, BF16, FP32)\n",
        "- Introduce the concept of mixed-precision computing\n",
        "- Use BitsAndBytes to quantize a pretrained model while loading it"
      ],
      "id": "4-4TsbHkp7VM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e1tbzNCp7VN"
      },
      "source": [
        "### Setup"
      ],
      "id": "_e1tbzNCp7VN"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODUm5BmEQhI",
        "outputId": "60a72311-9bf8-477a-a79c-ca4e185a02c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.3.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.48.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, bitsandbytes, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.3 datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.15.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# If you're running on Colab\n",
        "!pip install datasets bitsandbytes trl"
      ],
      "id": "kODUm5BmEQhI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIWRcytop7VO"
      },
      "outputs": [],
      "source": [
        "# If you're running on runpod.io's Jupyter Template\n",
        "#!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib"
      ],
      "id": "rIWRcytop7VO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7kb-6H_p7VO"
      },
      "source": [
        "### Imports"
      ],
      "id": "i7kb-6H_p7VO"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1d07gzUMp7VP",
        "outputId": "fa3d5d03-20e6-4b4e-8bd1-c0c8126cf56d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:bitsandbytes.cextension:Could not load bitsandbytes native library: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
            "    lib = get_native_library()\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
            "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 454, in LoadLibrary\n",
            "    return self._dlltype(name)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from accelerate import init_empty_weights\n",
        "from accelerate.utils.modeling import find_tied_parameters, get_mixed_precision_context_manager\n",
        "from accelerate.utils.operations import convert_outputs_to_fp32\n",
        "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4, LinearNF4\n",
        "from collections import Counter\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
        "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
        "from types import MethodType\n",
        "from matplotlib import pyplot as plt"
      ],
      "id": "1d07gzUMp7VP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fzp17xwp7VQ"
      },
      "source": [
        "### The Goal\n",
        "\n",
        "We quantize models to reduce their memory footprint. We can easily shrink the model’s size to a quarter or an eighth of its original size. Keep in mind, however, that the more a model is quantized (i.e., the fewer bit used\n",
        "to represent its weights), the more likely its performance will be negatively affected."
      ],
      "id": "0fzp17xwp7VQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLcdvTWpp7VQ"
      },
      "source": [
        "### Pre-Reqs\n",
        "\n",
        "| Type | Name | # bits | Nickname |\n",
        "|---|---|---|---|\n",
        "| FP32 | Floating Point | 32 | Full Precision |\n",
        "| BF16 | Brain Float | 16 | Half-Precision |\n",
        "| FP16 | Floating Point | 16 | Half-Precision |\n",
        "| INT8 | Integer | 8 | 8-bit Quantized |\n",
        "| FP4 | Floating Point | 4 | 4-bit Quantized |\n",
        "| NF4 | Normal Float | 4 | 4-bit Quantized |\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_sizes.png?raw=True)\n",
        "<center>Figure 2.1 - Data type’s size comparison</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/model_sizes.png?raw=True)\n",
        "<center>Figure 2.2 - Representing the same model using different data types</center>"
      ],
      "id": "XLcdvTWpp7VQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urV8uYEcp7VR"
      },
      "source": [
        "### Quantization in a Nutshell"
      ],
      "id": "urV8uYEcp7VR"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s2X_8WHrp7VR",
        "outputId": "3f5795f6-3017-455a-fff9-eda49d5f3af5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.2066), tensor(0.2097))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "weights = torch.randn(1000) * .07\n",
        "weights.min(), weights.max()"
      ],
      "id": "s2X_8WHrp7VR"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XMqIb-l1p7VS",
        "outputId": "a3070822-260c-443d-928c-51892a7cf6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]), tensor(0.1041))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "n_bins = 4\n",
        "bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "bin_width = bins[1]-bins[0]\n",
        "bins, bin_width"
      ],
      "id": "XMqIb-l1p7VS"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ri4iZIr9p7VS",
        "outputId": "6907a356-d900-4215-9224-f4d3a5107359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(weights, bins=bins)\n",
        "ax.set_xlabel('Values')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "Ri4iZIr9p7VS"
    },
    {
      "cell_type": "code",
      "source": [
        "weights.view(-1, 1).shape,bins.shape\n",
        "weights.view(-1, 1) > bins,(weights.view(-1, 1) > bins).shape"
      ],
      "metadata": {
        "id": "pc7BeJLitmzy",
        "outputId": "d400bd1c-27d8-49ab-9a0e-db18509e0f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pc7BeJLitmzy",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ True,  True, False, False, False],\n",
              "         [ True,  True,  True, False, False],\n",
              "         [ True,  True, False, False, False],\n",
              "         ...,\n",
              "         [ True,  True,  True, False, False],\n",
              "         [ True,  True,  True, False, False],\n",
              "         [ True,  True, False, False, False]]),\n",
              " torch.Size([1000, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wrVpr2rjp7VT",
        "outputId": "b56f2c60-f9ad-4582-b30a-8ca1589fba51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n",
            "tensor([1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "#compute the bin indexes for each weight.\n",
        "bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "print(weights[:20])\n",
        "print(bin_indexes[:20])"
      ],
      "id": "wrVpr2rjp7VT"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zod4WR_mp7VT",
        "outputId": "4edb8d7a-1299-46dc-af67-c2f5338d61ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(bin_indexes, bins=np.arange(n_bins+1)-.5)\n",
        "ax.set_xticks([0, 1, 2, 3])\n",
        "ax.set_xlabel('Bin Indexes')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "zod4WR_mp7VT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfOR5_hpp7VU"
      },
      "source": [
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{n_bins}=2^{\\text{n_bits}} \\implies \\text{n_bits} = \\log_2({\\text{n_bins}})\n",
        "$$\n",
        "\n",
        "<center>Equation 2.1 - Number of bits vs number of bins</center>"
      ],
      "id": "bfOR5_hpp7VU"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aXRyk1pwp7VU",
        "outputId": "35d223bf-44fa-4832-c34a-1cf8f3cf758b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2066, -0.1026,  0.0015,  0.1056]),\n",
              " tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "bin_values = bins[:-1]\n",
        "first_bin = bin_values[0]\n",
        "bin_values,bins"
      ],
      "id": "aXRyk1pwp7VU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGPES0Oep7VU"
      },
      "source": [
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{approx_value} = \\text{bin_index} * \\text{bin_width} + \\text{first_bin}\n",
        "$$\n",
        "\n",
        "<center>Equation 2.2 - Retrieving the (approximate) original value</center>"
      ],
      "id": "RGPES0Oep7VU"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pw4aw7ftp7VV",
        "outputId": "f988e9c8-a10f-44a8-fa0a-9fb43be99d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.arange(0, n_bins) * bin_width + first_bin"
      ],
      "id": "pw4aw7ftp7VV"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "umDH_uuQp7VV",
        "outputId": "b8cc504a-f1c4-4b9d-8c33-b43d504dd1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066,  0.0015, -0.1026,\n",
            "        -0.1026, -0.1026,  0.1056, -0.1026,  0.0015,  0.0015, -0.1026, -0.1026,\n",
            "         0.0015,  0.1056, -0.2066, -0.2066])\n"
          ]
        }
      ],
      "source": [
        "approx_values = bin_indexes * bin_width + first_bin\n",
        "print(approx_values[:20])"
      ],
      "id": "umDH_uuQp7VV"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YVMrU4I8p7VW",
        "outputId": "c6d4054c-4c4c-42d4-d768-bf282988e676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n"
          ]
        }
      ],
      "source": [
        "print(weights[:20])"
      ],
      "id": "YVMrU4I8p7VW"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4oYan0T1p7VW",
        "outputId": "e4e0b047-c887-4233-b3a8-cb5e6d03dfa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0615)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "mse_fn = nn.MSELoss()\n",
        "mse_fn(approx_values, weights).sqrt()"
      ],
      "id": "4oYan0T1p7VW"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S6WaJjrXp7VX"
      },
      "outputs": [],
      "source": [
        "def quantize(weights, n_bits=8):\n",
        "    assert n_bits <= 16, \"Using more bits may very slow execution and/or crashing.\"\n",
        "    n_bins = 2**n_bits\n",
        "    bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "    first_bin = bins[0]\n",
        "    bin_width = bins[1]-bins[0]\n",
        "    bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "    return bin_indexes, bin_width, first_bin\n",
        "\n",
        "def dequantize(bin_indexes, bin_width, first_bin):\n",
        "    approx_values = bin_indexes * bin_width + first_bin\n",
        "    return approx_values"
      ],
      "id": "S6WaJjrXp7VX"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gRFRP27vp7VX",
        "outputId": "0de98603-4e31-472a-f5e0-92f11f13b5fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-bit Quantization:\n",
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0615)\n",
            "\n",
            "\n",
            "4-bit Quantization:\n",
            "tensor([-0.0505,  0.0535, -0.0505,  0.0015, -0.0245, -0.1286])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0152)\n",
            "\n",
            "\n",
            "8-bit Quantization:\n",
            "tensor([-0.0359,  0.0714, -0.0261,  0.0080, -0.0131, -0.1058])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0010)\n",
            "\n",
            "\n",
            "16-bit Quantization:\n",
            "tensor([-0.0359,  0.0718, -0.0248,  0.0085, -0.0128, -0.1049])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0001)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n_bits in [2, 4, 8, 16]:\n",
        "    res = quantize(weights, n_bits=n_bits)\n",
        "    approx_values = dequantize(*res)\n",
        "    print(f'{n_bits}-bit Quantization:')\n",
        "    print(approx_values[:6])\n",
        "    print(weights[:6])\n",
        "    print(mse_fn(approx_values, weights).sqrt())\n",
        "    print('\\n')"
      ],
      "id": "gRFRP27vp7VX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7yVhbAUp7VX"
      },
      "source": [
        "****\n",
        "**ASIDE: Weight Distribution of Phi-3's Linear Layers**\n",
        "\n",
        "The following plots show the weight distribution of a large linear layer, `qkv_proj`, within the self-\n",
        "attention block in Phi-3. Other layers, such as `o_proj`, also located within the self-attention block, and\n",
        "`gate_up_proj` and `down_proj`, in the MLP block, have very similar weight distributions. This layer is\n",
        "present in every one of the 32 decoder blocks (indicated by the number in square brackets). You’ll notice\n",
        "that these millions of weights are concentrated within a very narrow range. But there are a few outliers as\n",
        "well, so each subplot also contains the actual range of observed weights in the corresponding layer.\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/self_attn.qkv_proj.png?raw=True)\n",
        "<center>Figure 2.5 - Weight distribution of Phi-3 layers</center>\n",
        "\n",
        "****"
      ],
      "id": "y7yVhbAUp7VX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a3vNTYWp7VX"
      },
      "source": [
        "### Half-Precision Weights"
      ],
      "id": "9a3vNTYWp7VX"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WtzJf5u8p7VX",
        "outputId": "7fc9d2f4-d703-4bce-9dd0-d475cda74190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048],\n",
            "       dtype=torch.float16)\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n"
          ]
        }
      ],
      "source": [
        "fp16_weights = weights.to(torch.float16)\n",
        "print(fp16_weights[:6])\n",
        "print(weights[:6])"
      ],
      "id": "WtzJf5u8p7VX"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JdU073O6p7VY",
        "outputId": "daf6468f-12ef-437a-b13b-3135af25aa55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4244e-05)\n"
          ]
        }
      ],
      "source": [
        "print(mse_fn(fp16_weights, weights).sqrt())"
      ],
      "id": "JdU073O6p7VY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mI_izQZp7VY"
      },
      "source": [
        "#### Living on the Edge"
      ],
      "id": "5mI_izQZp7VY"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JyWxJUAbp7VY",
        "outputId": "8737cebb-ee3c-4d4f-891f-ab4a88871624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8526e-16)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "torch.manual_seed(14)\n",
        "tiny_values = torch.randn(1000)*1e-5\n",
        "fp16_tiny_values = tiny_values.to(torch.float16)\n",
        "mse_fn(fp16_tiny_values, tiny_values)"
      ],
      "id": "JyWxJUAbp7VY"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CiS16o5Up7VZ",
        "outputId": "37351b06-00ee-45da-f84c-5fe228026c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.7241e-06,  1.1441e-05,  3.7199e-06, -1.1252e-06, -2.4735e-08])\n",
            "tensor([-2.7418e-06,  1.1444e-05,  3.6955e-06, -1.1325e-06, -0.0000e+00],\n",
            "       dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "print(tiny_values[155:160])\n",
        "print(fp16_tiny_values[155:160])"
      ],
      "id": "CiS16o5Up7VZ"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IHy1Pzh7p7VZ",
        "outputId": "f244497b-a2a4-45d6-f210-490e4952521a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([155074.0938,  64881.6602,   2729.5815, -40790.6562,  68846.7188])\n",
            "tensor([    inf,  64896.,   2730., -40800.,     inf], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(19)\n",
        "large_values = torch.randn(1000)*1e5\n",
        "fp16_large_values = large_values.to(torch.float16)\n",
        "print(large_values[:5])\n",
        "print(fp16_large_values[:5])"
      ],
      "id": "IHy1Pzh7p7VZ"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PjnURQHFp7Va",
        "outputId": "d9bc0fc3-f0a8-4697-cc9e-e8473639e93d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "fp16_info = torch.finfo(torch.float16)\n",
        "fp16_info"
      ],
      "id": "PjnURQHFp7Va"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DxJXh3Lqp7Va",
        "outputId": "3c85054c-103c-42af-eea8-f41b52546489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.960464477539063e-08"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "smallest_subnormal = fp16_info.smallest_normal * 2**-10\n",
        "smallest_subnormal"
      ],
      "id": "DxJXh3Lqp7Va"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edr2aB1Zp7Vb"
      },
      "source": [
        "### The Brain Float"
      ],
      "id": "Edr2aB1Zp7Vb"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2RpPy7N_p7Vc",
        "outputId": "69c914d1-a70d-4303-8281-3b3e253d9788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n",
            "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n"
          ]
        }
      ],
      "source": [
        "bf16_info = torch.finfo(torch.bfloat16)\n",
        "print(bf16_info)\n",
        "print(fp16_info)"
      ],
      "id": "2RpPy7N_p7Vc"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tI6C-Hugp7Vc",
        "outputId": "56d4d0a5-1b09-4dac-a0b1-b1ed134f930a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "fp32_info = torch.finfo(torch.float32)\n",
        "fp32_info"
      ],
      "id": "tI6C-Hugp7Vc"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0gr3RIPMp7Vd",
        "outputId": "84261c98-632b-4d45-c1c8-99340d9a51a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.555555582])\n",
            "tensor([0.555664062], dtype=torch.float16)\n",
            "tensor([0.554687500], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([0.555555555])\n",
        "torch.set_printoptions(precision=9)\n",
        "print(x)\n",
        "print(x.to(torch.float16))\n",
        "print(x.to(torch.bfloat16))\n",
        "torch.set_printoptions(precision=4)"
      ],
      "id": "0gr3RIPMp7Vd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTZgimiqp7Vd"
      },
      "source": [
        "|Type | Precision | Sub-normal | Min. | Max. |\n",
        "|---|---|---|---|---|\n",
        "|FP32 | e-08 | e-45 | e-38 | e+38 |\n",
        "|BF16 | e-03  | NA | e-38 | e+38 |\n",
        "|FP16 | e-04  | e-08  | e-05 | e+04 |"
      ],
      "id": "wTZgimiqp7Vd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxfuFT17p7Ve"
      },
      "source": [
        "### Loading Models\n",
        "\n",
        "****\n",
        "**Summary of \"Loading Models\"**\n",
        "- if supported by your GPU, use `torch.bfloat16` instead of `torch.float16` for all things 16-bit\n",
        " ```python\n",
        " supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        " dtypes16 = (torch.bfloat16 if supported else torch.float16)\n",
        " ```\n",
        "- when loading a pretrained model, always specify its `torch_dype` upfront\n",
        " ```python\n",
        " model = AutoModelForCausalLM.from_pretrained(repo_id, device_map='cuda:0', torch_dtype=torch.float32)\n",
        " ```\n",
        "****"
      ],
      "id": "kxfuFT17p7Ve"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7TBuyr3ep7Vf"
      },
      "outputs": [],
      "source": [
        "def get_parm_dtypes(iterable, top_k=3):\n",
        "    return Counter([p.dtype for p in iterable]).most_common(top_k)"
      ],
      "id": "7TBuyr3ep7Vf"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SLA8RF31p7Vg",
        "outputId": "d6c57e36-637e-4d93-c848-a0b97b770e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "2d78aa2cd7974e59bf89358667b32612",
            "803ca3b6461a4564bfea845fe6f202e9",
            "7b656037fabf4156ab216840b4efc9a4",
            "88866d014f4849d7b8b0d40a5d27e07f",
            "4b0aa871f6644dc6818bcf89beef6436",
            "83380ef79b1e457284e04badf06920f5",
            "6b05768d85a54de3ae91c17000a5af8b",
            "28edc6ec9be64669bd991ae0a5013f93",
            "9f72f8df00474ecdac66af076114b931",
            "faf08a65651c439d8bf6067906b0ea05",
            "67fc2baee07e441289118ab31d2b61ac",
            "46164338bb74446ba2688834d53c316e",
            "d34d587f7da94b42bbc682ef20e38019",
            "76c23dbb3ab14bc1a0c6f1171d899976",
            "f5b1715078f74ef69b473653c93147e7",
            "538b3040a39a43ac9da6677f11feb9c3",
            "c54a2b3debbb4211a19ea7b9b1a3885d",
            "7da4aac0a008415f91e2f9cf85c0e515",
            "cb472caf437a4108bf3c3f2cd3666cb9",
            "40e4001fe5044c8a8077f61660ec1496",
            "e172a5ccc56b4ab7a89b96957b7bb063",
            "73db665f269242f0aae48471ee9627a3"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d78aa2cd7974e59bf89358667b32612"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46164338bb74446ba2688834d53c316e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-af004da7d562>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/opt-350m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_memory_footprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_parm_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4243\u001b[0m                     \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                     \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4245\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4246\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4813\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4814\u001b[0m                         \u001b[0mfixed_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_state_dict_keys_on_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4815\u001b[0;31m                         new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4816\u001b[0m                             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4817\u001b[0m                             \u001b[0mfixed_state_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mset_module_tensor_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mset_module_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_quantized_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", device_map='cuda:0')\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "SLA8RF31p7Vg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRIxkn7Lp7Vh",
        "outputId": "ca13e341-99c4-4de6-b136-69a8b0add71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-rw-r-- 1 dvgodoy dvgodoy 662513657 May 11  2022 pytorch_model.bin\r\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin\n",
        "!ls -la pytorch_model.bin"
      ],
      "id": "tRIxkn7Lp7Vh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcdqKQj1p7Vi",
        "outputId": "1a4705c1-6b05-40a9-cda3-5a2a71c59e49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_dict = torch.load('pytorch_model.bin')\n",
        "get_parm_dtypes(iter(state_dict.values()))"
      ],
      "id": "hcdqKQj1p7Vi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXw6Yqs6p7Vi"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             torch_dtype=torch.float32)"
      ],
      "id": "wXw6Yqs6p7Vi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvLyD3GUp7Vj"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "batch = tokenizer(['This is a simple test'], return_tensors='pt')\n",
        "batch['labels'] = batch['input_ids']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch = {k: v.to(device) for k, v in batch.items()}"
      ],
      "id": "UvLyD3GUp7Vj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53fO4jBIp7Vj",
        "outputId": "bb5ecc11-f3c4-46b3-8455-156f36e7d291"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.8001, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "53fO4jBIp7Vj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n7mR5EUp7Vk"
      },
      "source": [
        "#### Half-Precision Models (16-bit)"
      ],
      "id": "_n7mR5EUp7Vk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPb_mFt8p7Vk",
        "outputId": "c9206b7d-3be0-46ee-97eb-5933578139d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "dtype16 = (torch.bfloat16 if supported else torch.float16)\n",
        "dtype16"
      ],
      "id": "FPb_mFt8p7Vk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdGzG8aEp7Vk",
        "outputId": "0f49e7a2-6ed8-4ddd-dcad-39a7518a1126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "662.392832\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "get_parm_dtypes(model.parameters())"
      ],
      "id": "RdGzG8aEp7Vk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMPM8o68p7Vk",
        "outputId": "21b34d79-72c7-47f1-f2e8-35018a52af4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "662.392832\n",
            "[(torch.float16, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             torch_dtype=dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "GMPM8o68p7Vk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uJY_56vp7Vk",
        "outputId": "ba0ed5dc-6b38-419c-e1ee-3aeb11e86c29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.8008, device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "1uJY_56vp7Vk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONNbY4IWp7Vl"
      },
      "source": [
        "### Mixed Precision"
      ],
      "id": "ONNbY4IWp7Vl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-WnHgZEp7Vl"
      },
      "outputs": [],
      "source": [
        "class MixedModel(nn.Module):\n",
        "    def __init__(self, dtype):\n",
        "        super().__init__()\n",
        "        self.a = nn.Linear(1000, 1000, dtype=dtype)\n",
        "        self.b = nn.Linear(1000, 1000, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.b(self.a(x))"
      ],
      "id": "6-WnHgZEp7Vl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zJ5LFFop7Vl",
        "outputId": "1455f000-e675-4bbc-f755-f141202ed9d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mixed32 = MixedModel(torch.float32)\n",
        "mixed32.to('cuda')"
      ],
      "id": "3zJ5LFFop7Vl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoMAQua8p7Vm",
        "outputId": "ce71df40-4861-4f20-b33b-1ccb80c27d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.41 ms ± 28 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "qoMAQua8p7Vm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sFAC3z2p7Vm",
        "outputId": "d3e8add7-9822-4afb-f122-71d31bb0c329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mixed16 = MixedModel(torch.float16)\n",
        "mixed16.to('cuda')"
      ],
      "id": "2sFAC3z2p7Vm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8pS47QRp7Vm",
        "outputId": "18c4ba52-409c-4ced-f4e7-158d1169c01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "248 µs ± 1.35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed16(torch.randn(1000, 1000, dtype=torch.float16, device='cuda'))"
      ],
      "id": "y8pS47QRp7Vm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvh1qZ--p7Vn",
        "outputId": "7953ca35-008c-4339-f1c2-6a63d77e97d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "277 µs ± 1.29 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    %timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "Qvh1qZ--p7Vn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BBRNmkbp7Vn",
        "outputId": "b6b7fd84-3ab0-49d0-c52e-c2199e2868d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    res16 = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "\n",
        "res32 = res16.float()"
      ],
      "id": "7BBRNmkbp7Vn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdpuOCKcp7Vn"
      },
      "outputs": [],
      "source": [
        "autocast_context = torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
        "# original forward method\n",
        "model_forward_func = mixed32.forward.__func__\n",
        "# wrapping the method with the context manager\n",
        "new_forward = autocast_context(model_forward_func)\n",
        "# assigning the wrapped method back to the model\n",
        "mixed32.forward = MethodType(new_forward, mixed32)"
      ],
      "id": "mdpuOCKcp7Vn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xKR8hHnp7Vn",
        "outputId": "5e685615-bae1-4dfe-fac5-2863a11e17fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "3xKR8hHnp7Vn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkAUnCxbp7Vo"
      },
      "outputs": [],
      "source": [
        "mixed32.forward = MethodType(convert_outputs_to_fp32(mixed32.forward.__func__), mixed32)"
      ],
      "id": "RkAUnCxbp7Vo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0urwhfRp7Vo",
        "outputId": "d784ba00-4e16-48ae-b0a7-50cf2d30ce6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "q0urwhfRp7Vo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO3QJFVkp7Vo",
        "outputId": "da50928e-a6d7-4b84-f3a5-6dcf707ac856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "371 µs ± 1.27 µs per loop  (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "FO3QJFVkp7Vo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCw4X3r9p7Vo"
      },
      "source": [
        "### BitsAndBytes\n",
        "\n",
        "[BitsAndBytes](https://huggingface.co/docs/bitsandbytes/main/en/index) is your go-to package for quantization. From its documentation:\n",
        "\n",
        "\"_bitsandbytes enables accessible large language models via k-bit quantization for PyTorch. bitsandbytes provides three main features for dramatically reducing memory consumption for inference and training:_\n",
        "\n",
        "- _8-bit optimizers uses block-wise quantization to maintain 32-bit performance at a small fraction of the memory cost._\n",
        "- _LLM.Int() or 8-bit quantization enables large language model inference with only half the required memory and without any performance degradation. This method is based on vector-wise quantization to quantize most features to 8-bits and separately treating outliers with 16-bit matrix multiplication._\n",
        "- _QLoRA or 4-bit quantization enables large language model training with several memory-saving techniques that don’t compromise performance. This method quantizes a model to 4-bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training._\""
      ],
      "id": "XCw4X3r9p7Vo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Em0_6hPOp7Vp",
        "outputId": "71c728cd-bf72-4d81-ed05-c28d6ac14287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BitsAndBytesConfig {\n",
              "  \"_load_in_4bit\": false,\n",
              "  \"_load_in_8bit\": false,\n",
              "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "  \"bnb_4bit_quant_type\": \"fp4\",\n",
              "  \"bnb_4bit_use_double_quant\": false,\n",
              "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "  \"llm_int8_has_fp16_weight\": false,\n",
              "  \"llm_int8_skip_modules\": null,\n",
              "  \"llm_int8_threshold\": 6.0,\n",
              "  \"load_in_4bit\": false,\n",
              "  \"load_in_8bit\": false,\n",
              "  \"quant_method\": \"bitsandbytes\"\n",
              "}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig()\n",
        "bnb_config"
      ],
      "id": "Em0_6hPOp7Vp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcLIpF5Ap7Vp"
      },
      "source": [
        "#### 8-Bit Quantization\n",
        "\n",
        "\"_LLM.int8() is a quantization method that doesn’t degrade performance which makes large model inference more accessible. The key is to extract the outliers from the inputs and weights and multiply them in 16-bit. All other values are multiplied in 8-bit and quantized to Int8 before being dequantized back to 16-bits. The outputs from the 16-bit and 8-bit multiplication are combined to produce the final output._\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)\n",
        "\n",
        "****\n",
        "**Summary of \"8-Bit Quantization\"**\n",
        "- load an 8-bit quantized model in a few lines of code:\n",
        "  ```python\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                                 device_map='cuda:0',\n",
        "                                                 torch_dtype=torch.float32,\n",
        "                                                 quantization_config=bnb_config)\n",
        "  ```\n",
        "  - quantization modifies the default type of non-quantized layers to `torch.float16` unless we actively provide the `torch_dtype` argument when calling the `from_pretrained()` method\n",
        "- 8-bit quantization replaces all linear layers except for:\n",
        "  - layers with tied (shared) weights\n",
        "  - the last layer in the model\n",
        "  - any layer named `lm_head`\n",
        "- if you want to skip additional modules, use the `llm_int8_skip_modules` configuration argument and make sure to manually include the layers with tied (shared) weights to avoid errors\n",
        "- computation (inside the quantized layers) happens in `torch.float16`\n",
        "****"
      ],
      "id": "NcLIpF5Ap7Vp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dHS3hxZp7Vp",
        "outputId": "53499c8c-f3df-4251-d439-551596db9b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "359.354368\n",
            "[(torch.float16, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "bnb_config_q8 = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_q8 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8)\n",
        "print(model_q8.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8.parameters()))"
      ],
      "id": "5dHS3hxZp7Vp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgNsqMCBp7Vq",
        "outputId": "c92a27d2-b67f-4791-93f2-2194931ca83d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you may not get a NaN back, as it depends on the environment\n",
        "out = model_q8(**batch)\n",
        "out.loss"
      ],
      "id": "hgNsqMCBp7Vq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIp6Tv-9p7Vq",
        "outputId": "2f96b038-bf1d-4b32-c44d-4d1ea2813ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "415.670272\n",
            "[(torch.float32, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q8_32 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8,\n",
        "                                                torch_dtype=torch.float32)\n",
        "print(model_q8_32.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8_32.parameters()))"
      ],
      "id": "CIp6Tv-9p7Vq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv_dZPW2p7Vr",
        "outputId": "8d470e5c-38e9-4182-9941-2aa6d50974f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(3.8024, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q8_32(**batch)\n",
        "out.loss"
      ],
      "id": "Qv_dZPW2p7Vr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7jPUS6pp7Vr"
      },
      "source": [
        "##### Quantized Linear Layers"
      ],
      "id": "h7jPUS6pp7Vr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVjfcaRJp7Vr",
        "outputId": "1bc35e3b-b01a-496e-bfe6-5f8e2a9e7ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q8_32.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "dVjfcaRJp7Vr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUartByhp7Vs",
        "outputId": "71c57a21-e6d9-40bb-8d82-ea2c2db44892"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear8bitLt(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_layer = dec_layer.self_attn.k_proj\n",
        "q8_layer"
      ],
      "id": "LUartByhp7Vs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbeYUQm-p7Vs",
        "outputId": "51249f2b-abe7-439c-902f-3843a3735439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -67, -113,  -89,  ...,   65,  -16,  -87],\n",
              "                      [  60,  120,   90,  ...,  -50,   32,   80],\n",
              "                      [  47,  127,   86,  ...,  -34,    8,   90],\n",
              "                      ...,\n",
              "                      [ -65,   65,   34,  ...,  -64,   35,   64],\n",
              "                      [  57,   67,   21,  ...,   63,  -64,  -64],\n",
              "                      [ -64,   63,  -11,  ...,  -64,   34,   63]], device='cuda:0',\n",
              "                     dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.1250, 0.1252, 0.1250,  ..., 0.1252, 0.1250, 0.1254], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_state = q8_layer.state_dict()\n",
        "q8_state"
      ],
      "id": "kbeYUQm-p7Vs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSh60hwcp7Vt",
        "outputId": "88321f71-50a5-433a-d988-0a0bf0423a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding(50272, 512, padding_idx=1)\n",
            "Linear(in_features=512, out_features=50272, bias=False)\n"
          ]
        }
      ],
      "source": [
        "print(model.model.decoder.embed_tokens)\n",
        "print(model.lm_head)"
      ],
      "id": "KSh60hwcp7Vt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT0h_vudp7Vt",
        "outputId": "5d16998c-ca1a-41f6-96b7-9fa9e9d3b128"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(model.model.decoder.embed_tokens.weight,\n",
        "               model.lm_head.weight)"
      ],
      "id": "ZT0h_vudp7Vt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "287RiyHgp7Vt",
        "outputId": "59f88aad-cc2a-44b3-8824-d39b081d630f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, [['lm_head.weight', 'model.decoder.embed_tokens.weight']])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
        "\n",
        "config.tie_word_embeddings, find_tied_parameters(model)"
      ],
      "id": "287RiyHgp7Vt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omzkkgjap7Vu",
        "outputId": "3118c319-0b9c-4ff3-be9f-84e6fe347142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(..., device='meta', size=(50272, 512), requires_grad=True)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with init_empty_weights(): # loads meta tensors only\n",
        "    empty_model = AutoModelForCausalLM.from_config(config)\n",
        "\n",
        "empty_model.lm_head.weight"
      ],
      "id": "omzkkgjap7Vu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HoPr3Ccp7Vu",
        "outputId": "752019f7-1bd9-498b-a407-68083644c971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lm_head', 'model.decoder.embed_tokens']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skip_modules = get_keys_to_not_convert(empty_model)\n",
        "skip_modules"
      ],
      "id": "3HoPr3Ccp7Vu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8SgZ3BFp7Vu",
        "outputId": "8a21742a-1571-482a-df59-f3e27dcfbf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lm_head: torch.float32\n",
            "model.decoder.embed_tokens: torch.float32\n"
          ]
        }
      ],
      "source": [
        "for module in skip_modules:\n",
        "    print(f'{module}: {next(model_q8_32.get_submodule(module).parameters()).dtype}')"
      ],
      "id": "d8SgZ3BFp7Vu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju-6OarRp7Vv"
      },
      "source": [
        "#### `llm_int8_skip_modules`\n",
        "\n",
        "If your model has tied weights, and you choose to use your own list of modules to skip, you\n",
        "must add one of the tied layers to your list. If you don’t, you may get the following\n",
        "exception:\n",
        "\n",
        "***\n",
        "`AttributeError: 'Parameter' object has no attribute 'SCB'`\n",
        "***\n",
        "\n",
        "```python\n",
        "# This configuration WILL raise an exception\n",
        "# while trying to load weights for the tied layer\n",
        "# bnb_config_skip = BitsAndBytesConfig(load_in_8bit=True,\n",
        "#                                      llm_int8_skip_modules=['o_proj'])\n",
        "\n",
        "# This configuration works fine because\n",
        "# the tied layer, lm_head, is in the list\n",
        "bnb_config_skip = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        llm_int8_skip_modules=['o_proj', 'lm_head'])\n",
        "\n",
        "model_skip = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                  device_map='cuda:0',\n",
        "                                                  torch_dtype=torch.float32,\n",
        "                                                  quantization_config=bnb_config_skip)\n",
        "```"
      ],
      "id": "Ju-6OarRp7Vv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGc39v60p7Vv"
      },
      "source": [
        "##### 8-bit Layers\n",
        "\n",
        "\"*In order to quantize a linear layer one should first load the original fp16 / bf16 weights into the Linear8bitLt module, then call int8_module.to(\"cuda\") to quantize the fp16 weights.*\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)"
      ],
      "id": "AGc39v60p7Vv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px3iWa8Lp7Vv",
        "outputId": "eab8dff0-034f-4db4-b55b-aa4199e4d117"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.2220, -0.0085,  0.3072, -0.2097,  0.0531,  0.1224,  0.0525, -0.2350,\n",
              "                        0.0456,  0.2687],\n",
              "                      [-0.1459,  0.1786, -0.1443, -0.0233,  0.1689,  0.0015, -0.2514,  0.1644,\n",
              "                        0.1920,  0.1678],\n",
              "                      [ 0.2346,  0.1411,  0.2128,  0.0519,  0.2147, -0.2786, -0.0433, -0.0364,\n",
              "                       -0.1504,  0.0823],\n",
              "                      [ 0.2388, -0.2134, -0.1620, -0.1023,  0.2433, -0.2680,  0.3099, -0.1933,\n",
              "                       -0.0471, -0.0391],\n",
              "                      [-0.1273,  0.2197, -0.0136, -0.1938, -0.1746,  0.0404,  0.0711, -0.1730,\n",
              "                        0.0539, -0.1992],\n",
              "                      [-0.0051,  0.1373, -0.0267, -0.0907, -0.0107,  0.1108, -0.1566,  0.0172,\n",
              "                        0.2075, -0.0028],\n",
              "                      [ 0.2082, -0.2857, -0.2640, -0.1436,  0.1704,  0.1908, -0.2350,  0.1187,\n",
              "                       -0.0568,  0.0916],\n",
              "                      [ 0.2974, -0.3061,  0.0559,  0.1899,  0.0265, -0.1893, -0.0582, -0.0943,\n",
              "                        0.2451,  0.2825],\n",
              "                      [-0.1241, -0.3106, -0.1002, -0.1745,  0.2693,  0.2985,  0.1633, -0.0270,\n",
              "                       -0.3049,  0.0227],\n",
              "                      [-0.1217,  0.0035, -0.1481, -0.0330,  0.1787,  0.3123,  0.2600, -0.1720,\n",
              "                        0.2059,  0.2057]])),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854]))])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "\n",
        "torch.manual_seed(11)\n",
        "fp_layer = nn.Linear(n_in, n_out)\n",
        "\n",
        "int8_layer = Linear8bitLt(n_in, n_out, has_fp16_weights=False)\n",
        "\n",
        "int8_layer.load_state_dict(fp_layer.state_dict())\n",
        "int8_layer.state_dict()"
      ],
      "id": "Px3iWa8Lp7Vv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb_ZA3wAp7Vw",
        "outputId": "10da6b39-e87d-41f7-a2aa-cb6b7e8bc922"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -92,   -4,  127,  -87,   22,   51,   22,  -97,   19,  111],\n",
              "                      [ -74,   90,  -73,  -12,   85,    1, -127,   83,   97,   85],\n",
              "                      [ 107,   64,   97,   24,   98, -127,  -20,  -17,  -69,   38],\n",
              "                      [  98,  -87,  -66,  -42,  100, -110,  127,  -79,  -19,  -16],\n",
              "                      [ -74,  127,   -8, -112, -101,   23,   41, -100,   31, -115],\n",
              "                      [  -3,   84,  -16,  -56,   -7,   68,  -96,   11,  127,   -2],\n",
              "                      [  93, -127, -117,  -64,   76,   85, -104,   53,  -25,   41],\n",
              "                      [ 123, -127,   23,   79,   11,  -79,  -24,  -39,  102,  117],\n",
              "                      [ -51, -127,  -41,  -71,  110,  122,   67,  -11, -125,    9],\n",
              "                      [ -50,    1,  -60,  -13,   73,  127,  106,  -70,   84,   84]],\n",
              "                     device='cuda:0', dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854], device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.3071, 0.2515, 0.2786, 0.3098, 0.2197, 0.2075, 0.2856, 0.3062, 0.3105,\n",
              "                      0.3123], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int8_layer = int8_layer.to(0) # Quantization happens here\n",
        "int8_state = int8_layer.state_dict()\n",
        "int8_state"
      ],
      "id": "Sb_ZA3wAp7Vw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O6GCvVnp7Vw"
      },
      "source": [
        "#### 4-bit Quantization\n",
        "\n",
        "\"*QLoRA is a finetuning method that quantizes a model to 4-bits and adds a set of low-rank adaptation (LoRA) weights to the model and tuning them through the quantized weights. This method also introduces a new data type, 4-bit NormalFloat (LinearNF4) in addition to the standard Float4 data type (LinearFP4). LinearNF4 is a quantization data type for normally distributed data and can improve performance.*\"\n",
        "\n",
        "Source: [4-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear4bit)\n",
        "\n",
        "****\n",
        "**Summary of \"4-Bit Quantization\"**\n",
        "- squeeze the most of a 4-bit quantized model by using the normal float (NF4) type and double quantization\n",
        "  ```python\n",
        "  supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "  compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "  nf4_config = BitsAndBytesConfig(\n",
        "     load_in_4bit=True,\n",
        "     bnb_4bit_quant_type=\"nf4\",\n",
        "     bnb_4bit_use_double_quant=True,\n",
        "     bnb_4bit_compute_dtype=compute_dtype\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                               device_map='cuda:0',\n",
        "                                               torch_dtype=torch.float32,\n",
        "                                               quantization_config=nf4_config)\n",
        "  ```\n",
        "- computation happens (inside the quantized layers) in the specified type (`bnb_4bit_compute_dtype`):\n",
        "FP32 is better than BF16, which is better than FP16.\n",
        "****"
      ],
      "id": "6O6GCvVnp7Vw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB07Mr2xp7Vw"
      },
      "outputs": [],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=compute_dtype\n",
        ")"
      ],
      "id": "tB07Mr2xp7Vw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA-LTsCgp7Vx"
      },
      "source": [
        "**The Secret Lives of `Dtypes`**\n",
        "\n",
        "| Regular Model | Quantized Model |\n",
        "|---|---|\n",
        "| ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_regular.png?raw=True) | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_qt.png?raw=True) |\n",
        "| <center>Figure 2.6 - Data types flowing through a regular model</center> | <center>Figure 2.7 - Data types flowing through a quantized model</center> |"
      ],
      "id": "MA-LTsCgp7Vx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL7FSpTAp7Vx",
        "outputId": "b9e379d7-79f8-4027-b6b7-71320e608581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "264.15104\n",
            "[(torch.float32, 242), (torch.uint8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q4 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                torch_dtype=torch.float32,\n",
        "                                                quantization_config=nf4_config)\n",
        "print(model_q4.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q4.parameters()))"
      ],
      "id": "AL7FSpTAp7Vx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXWcbzLMp7Vy",
        "outputId": "edf0a4f6-4777-40b3-d242-c59df59d9f98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.7016, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q4(**batch)\n",
        "out.loss"
      ],
      "id": "KXWcbzLMp7Vy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecI8opSnp7Vy",
        "outputId": "422d8e27-6df5-429f-a6d6-bd6c98a68acf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q4.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "ecI8opSnp7Vy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNPUXBTfp7Vy",
        "outputId": "59bb9f1c-c876-462f-dd54-026c377670f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear4bit(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer = dec_layer.self_attn.k_proj\n",
        "q4_layer"
      ],
      "id": "NNPUXBTfp7Vy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSONry8yp7Vz",
        "outputId": "4339e122-94d1-4e61-b66a-c5bfd931eca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 32],\n",
              "                      [ 29],\n",
              "                      [208],\n",
              "                      ...,\n",
              "                      [ 66],\n",
              "                      [ 34],\n",
              "                      [172]], device='cuda:0', dtype=torch.uint8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0', dtype=torch.float16)),\n",
              "             ('weight.absmax',\n",
              "              tensor([230, 230,  30,  ...,   1,  26, 191], device='cuda:0',\n",
              "                     dtype=torch.uint8)),\n",
              "             ('weight.quant_map',\n",
              "              tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "                       0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "                     device='cuda:0')),\n",
              "             ('weight.nested_absmax',\n",
              "              tensor([0.0077, 0.0142, 0.0153, 0.0138, 0.0399, 0.0409, 0.0417, 0.0426, 0.0053,\n",
              "                      0.0053, 0.0053, 0.0053, 0.0051, 0.0051, 0.0051, 0.0053, 0.0195, 0.0269,\n",
              "                      0.0223, 0.0195, 0.0053, 0.0053, 0.0054, 0.0054, 0.0317, 0.0315, 0.0306,\n",
              "                      0.0320, 0.0262, 0.0265, 0.0230, 0.0296, 0.0051, 0.0065, 0.0050, 0.0050,\n",
              "                      0.0051, 0.0053, 0.0050, 0.0051, 0.0056, 0.0056, 0.0056, 0.0056, 0.0428,\n",
              "                      0.0410, 0.0405, 0.0422, 0.0397, 0.0402, 0.0394, 0.0414, 0.0204, 0.0106,\n",
              "                      0.0140, 0.0078, 0.0406, 0.0349, 0.0359, 0.0418, 0.0503, 0.0499, 0.0470,\n",
              "                      0.0458], device='cuda:0')),\n",
              "             ('weight.nested_quant_map',\n",
              "              tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
              "                      -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
              "                      -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
              "                      -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
              "                      -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
              "                      -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
              "                      -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
              "                      -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
              "                      -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
              "                      -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
              "                      -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
              "                      -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
              "                      -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
              "                      -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
              "                      -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
              "                      -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
              "                      -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
              "                      -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
              "                      -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
              "                      -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
              "                      -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
              "                      -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
              "                      -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
              "                      -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
              "                      -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
              "                      -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
              "                       7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
              "                       1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
              "                       7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
              "                       2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
              "                       5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
              "                       8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
              "                       1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
              "                       2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
              "                       4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
              "                       5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
              "                       7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
              "                       8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
              "                       9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
              "                       1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
              "                       2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
              "                       3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
              "                       3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
              "                       4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
              "                       5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
              "                       5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
              "                       6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
              "                       7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
              "                       7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
              "                       8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
              "                       9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
              "                       1.0000e+00], device='cuda:0')),\n",
              "             ('weight.quant_state.bitsandbytes__nf4',\n",
              "              tensor([123,  34, 113, 117,  97, 110, 116,  95, 116, 121, 112, 101,  34,  58,\n",
              "                       32,  34, 110, 102,  52,  34,  44,  32,  34,  98, 108, 111,  99, 107,\n",
              "                      115, 105, 122, 101,  34,  58,  32,  54,  52,  44,  32,  34, 100, 116,\n",
              "                      121, 112, 101,  34,  58,  32,  34, 102, 108, 111,  97, 116,  49,  54,\n",
              "                       34,  44,  32,  34, 115, 104,  97, 112, 101,  34,  58,  32,  91,  49,\n",
              "                       48,  50,  52,  44,  32,  49,  48,  50,  52,  93,  44,  32,  34, 110,\n",
              "                      101, 115, 116, 101, 100,  95,  98, 108, 111,  99, 107, 115, 105, 122,\n",
              "                      101,  34,  58,  32,  50,  53,  54,  44,  32,  34, 110, 101, 115, 116,\n",
              "                      101, 100,  95, 100, 116, 121, 112, 101,  34,  58,  32,  34, 102, 108,\n",
              "                      111,  97, 116,  51,  50,  34,  44,  32,  34, 110, 101, 115, 116, 101,\n",
              "                      100,  95, 111, 102, 102, 115, 101, 116,  34,  58,  32,  48,  46,  49,\n",
              "                       49,  57,  57,  56,  49,  55,  50,  49,  48,  52,  51,  53,  56,  54,\n",
              "                       55,  51, 125], dtype=torch.uint8))])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer.state_dict()"
      ],
      "id": "HSONry8yp7Vz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvcitl4qp7Vz"
      },
      "source": [
        "##### FP4 vs NF4 Layers"
      ],
      "id": "gvcitl4qp7Vz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ9DWh2jp7Vz",
        "outputId": "20b73d2a-edbd-46d7-99d7-346103707e0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "torch.manual_seed(11)\n",
        "fp16_layer = nn.Linear(n_in, n_out)\n",
        "fp16_layer"
      ],
      "id": "mJ9DWh2jp7Vz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW7jQwsUp7V0",
        "outputId": "b121eb95-3976-4563-a2e8-8f5bfacb73e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = LinearFP4(n_in, n_out)\n",
        "fp4_layer.load_state_dict(fp16_layer.state_dict())\n",
        "\n",
        "nf4_model = LinearNF4(n_in, n_out)\n",
        "nf4_model.load_state_dict(fp16_layer.state_dict())"
      ],
      "id": "sW7jQwsUp7V0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgdpBElop7V0",
        "outputId": "4a39a6e7-42c8-4f97-9108-67e034e6262c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
              "          0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = fp4_layer.to(0) # Quantization happens here\n",
        "fp4_state = fp4_layer.state_dict()\n",
        "\n",
        "fp4_state['weight.quant_map'], fp4_state['weight'].shape"
      ],
      "id": "hgdpBElop7V0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBB5VR0dp7V0",
        "outputId": "505d8d88-4b9a-44d2-be18-730309fe71ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'FP4 quantization')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(fp4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('FP4 quantization')"
      ],
      "id": "cBB5VR0dp7V0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmE_tkjPp7V1",
        "outputId": "d734f11d-5a97-44ec-c4b3-f5f07c2aee52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nf4_model = nf4_model.to(0) # Quantization happens here\n",
        "nf4_state = nf4_model.state_dict()\n",
        "\n",
        "nf4_state['weight.quant_map'], nf4_state['weight'].shape"
      ],
      "id": "VmE_tkjPp7V1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9qoQqUqp7V1",
        "outputId": "d52f135a-b1d5-4eea-c943-168035a06d1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'NF4 quantization')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(nf4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('NF4 quantization')"
      ],
      "id": "a9qoQqUqp7V1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnHKEDvLp7V1"
      },
      "source": [
        "### Coming Up in \"Fine-Tuning LLMs\"\n",
        "\n",
        "As huge linear layers are being replaced by their quantized versions to reduce the model’s memory footprint, a\n",
        "new issue arises. These quantized layers cannot be easily updated, thus rendering fine-tuning next to\n",
        "impossible. Could a new kind of layer be the solution to this conundrum? Find out in the next thrilling chapter\n",
        "of \"Fine-Tuning LLMs.\""
      ],
      "id": "XnHKEDvLp7V1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d78aa2cd7974e59bf89358667b32612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_803ca3b6461a4564bfea845fe6f202e9",
              "IPY_MODEL_7b656037fabf4156ab216840b4efc9a4",
              "IPY_MODEL_88866d014f4849d7b8b0d40a5d27e07f"
            ],
            "layout": "IPY_MODEL_4b0aa871f6644dc6818bcf89beef6436"
          }
        },
        "803ca3b6461a4564bfea845fe6f202e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83380ef79b1e457284e04badf06920f5",
            "placeholder": "​",
            "style": "IPY_MODEL_6b05768d85a54de3ae91c17000a5af8b",
            "value": "config.json: 100%"
          }
        },
        "7b656037fabf4156ab216840b4efc9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28edc6ec9be64669bd991ae0a5013f93",
            "max": 644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f72f8df00474ecdac66af076114b931",
            "value": 644
          }
        },
        "88866d014f4849d7b8b0d40a5d27e07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faf08a65651c439d8bf6067906b0ea05",
            "placeholder": "​",
            "style": "IPY_MODEL_67fc2baee07e441289118ab31d2b61ac",
            "value": " 644/644 [00:00&lt;00:00, 36.2kB/s]"
          }
        },
        "4b0aa871f6644dc6818bcf89beef6436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83380ef79b1e457284e04badf06920f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b05768d85a54de3ae91c17000a5af8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28edc6ec9be64669bd991ae0a5013f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f72f8df00474ecdac66af076114b931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faf08a65651c439d8bf6067906b0ea05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67fc2baee07e441289118ab31d2b61ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46164338bb74446ba2688834d53c316e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d34d587f7da94b42bbc682ef20e38019",
              "IPY_MODEL_76c23dbb3ab14bc1a0c6f1171d899976",
              "IPY_MODEL_f5b1715078f74ef69b473653c93147e7"
            ],
            "layout": "IPY_MODEL_538b3040a39a43ac9da6677f11feb9c3"
          }
        },
        "d34d587f7da94b42bbc682ef20e38019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54a2b3debbb4211a19ea7b9b1a3885d",
            "placeholder": "​",
            "style": "IPY_MODEL_7da4aac0a008415f91e2f9cf85c0e515",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "76c23dbb3ab14bc1a0c6f1171d899976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb472caf437a4108bf3c3f2cd3666cb9",
            "max": 662513657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40e4001fe5044c8a8077f61660ec1496",
            "value": 662513657
          }
        },
        "f5b1715078f74ef69b473653c93147e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e172a5ccc56b4ab7a89b96957b7bb063",
            "placeholder": "​",
            "style": "IPY_MODEL_73db665f269242f0aae48471ee9627a3",
            "value": " 663M/663M [00:10&lt;00:00, 43.2MB/s]"
          }
        },
        "538b3040a39a43ac9da6677f11feb9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54a2b3debbb4211a19ea7b9b1a3885d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da4aac0a008415f91e2f9cf85c0e515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb472caf437a4108bf3c3f2cd3666cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e4001fe5044c8a8077f61660ec1496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e172a5ccc56b4ab7a89b96957b7bb063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73db665f269242f0aae48471ee9627a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}